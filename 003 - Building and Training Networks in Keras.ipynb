{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 001 - Building and Training Networks in Keras\n",
    "This workbook contains a set of exercises designed to get you comfortable with building and training Neural Networks using the Keras API.\n",
    "\n",
    "We will cover:\n",
    " - Creating Single layer networks\n",
    " - Creating Multi-Layer networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Display graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingVsModel(X, y, model):\n",
    "  predicted = model.predict(X)\n",
    "\n",
    "  # Plot the data out\n",
    "  plt.plot(X, y, 'o', color='red', label=\"Expected Value\")\n",
    "  plt.plot(X, predicted, 'x', color='blue', label=\"Predicted Value\")\n",
    "  plt.title(\"Expected vs Model Predicted\")\n",
    "  plt.legend()\n",
    "  plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "In this exercise you will use a simple data set and create a single layer network.\n",
    "\n",
    "The data has the relationship that the output (_y_data_) is __twice the input plus 5__\n",
    "\n",
    "We want to train a network to learn this sequence and be able to predict with reasonable accuracy the next values in the sequence - for example, if given the value 11 we would expect the output to be 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "y_data = [7.0, 9.0, 11.0, 13.0, 15.0, 17.0, 19.0, 21.0, 23.0, 25.0]\n",
    "\n",
    "# Convert these to numpy arrays\n",
    "X_data = np.array(X_data, dtype=float)\n",
    "y_data = np.array(y_data, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have started the model by defining it as a Sequence model. Your task is to complete the line:\n",
    "\n",
    "`model.add( None)` \n",
    "\n",
    "by replacing the text `None` with a defintion for layer.\n",
    "\n",
    "As a hint, we can define a layer using the syntax\n",
    "\n",
    "`keras.layers.Dense(units=number_of_units, input_shape=[size_of_input])`\n",
    "\n",
    "You will need to replace __number_of_units__ and __size_of_feature__ with values based on:\n",
    "- _number_of_units_: For this exercise set this to 1\n",
    "- _size_of_input_: this is the size (shape) of an individual input.\n",
    "\n",
    "__Hint__: This is almost identical to the example given in 'Developing DL Intuition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# YOUR CHANGES START HERE\n",
    "model.add( None)\n",
    "# YOUR CHANGES END HERE\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(tf.keras.optimizers.RMSprop(0.001), loss='mean_squared_error')\n",
    "\n",
    "# Produce a sumary of our model\n",
    "print(\"\\nModel Summary\\n\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the model we want to train the model. We have completed most of this statement, but you need to decide on how many _epochs_ to train for.\n",
    "\n",
    "To do this, change the value of _epochs_ from _None_ to some value (greater than 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_data, y_data, epochs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how good our model is.\n",
    "\n",
    "If the model, hasn't performed as well as you want it to, then re-run the steps in the exercise and train with a higher number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrainingVsModel(X_data, y_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the model against some values it has not seen before. How well did it do?\n",
    "\n",
    "Try out some other values to see how well the model has learned the relationship __(2 * x) + 5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value from 11 if you want to try other values and re-run the cell\n",
    "value_to_predict = 11\n",
    "\n",
    "predicted = model.predict(value_to_predict)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In this exercise we have data were each training instance consists of more than 3 values and we want to train a model that learns the relationship between these values and the output value.\n",
    "\n",
    "The relationship between the input and output is that the output is the middle value of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [\n",
    "    [1.0, 5.0, 2.0], \n",
    "    [4.0, 4.0, 5.0], \n",
    "    [7.0, 3.0, 8.0],\n",
    "    [10.0, 3.0, 6.0],\n",
    "    [4.0, 9.0, 5.0],\n",
    "    [7.0, 2.0, 6.0],\n",
    "    [1.0, 1.0, 3.0],\n",
    "    [12.0, 4.0, 2.0],\n",
    "    [6.0, 6.0, 1.0],\n",
    "    [3.0, 3.0, 3.0]\n",
    "]\n",
    "# Here we are using some Python (List Comprehension) to calculate the values for us\n",
    "y_data = [y  for [x, y, z] in X_data]\n",
    "print(y_data)\n",
    "\n",
    "# Convert these to numpy arrays\n",
    "X_data = np.array(X_data, dtype=float)\n",
    "y_data = np.array(y_data, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build our model - this is the same as in the previous exercise so refer back to your work to get some hints.\n",
    "\n",
    "As before your task is to complete the line:\n",
    "\n",
    "`model.add( None)` \n",
    "\n",
    "by replacing the text `None` with a defintion for layer.\n",
    "\n",
    "We can define a layer using the syntax\n",
    "\n",
    "`keras.layers.Dense(units=number_of_units, input_shape=[size_of_input])`\n",
    "\n",
    "You will need to replace __number_of_units__ and __size_of_feature__ with values based on:\n",
    "- _number_of_units_: this defines how many nodes you want in your layer. Set this to 1.\n",
    "- _size_of_input_: this is the size (shape) of an individual input.\n",
    "\n",
    "A key difference between the previous model and this one is that previously you had 1 data item for each training example however now we have 3 and so our _size_of_input_ needs to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# YOUR CHANGES START HERE\n",
    "model.add( None)\n",
    "# YOUR CHANGES END HERE\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(tf.keras.optimizers.RMSprop(0.001), loss='mean_squared_error')\n",
    "\n",
    "# Produce a sumary of our model\n",
    "print(\"\\nModel Summary\\n\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_data, y_data, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how good our model is at predicting the output for a given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value if you want to try other values and re-run the cell\n",
    "value_to_predict = np.array([[1.0, 5.0, 1.0]], dtype=float)\n",
    "\n",
    "predicted = model.predict(value_to_predict)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "In this we will use a more complex set of data and create a multi-layer network.\n",
    "\n",
    "In this exercise we are less interested in the accuracy of the model (we'll return to this dataset again in a later lesson). For this exercise we are only interested in practicing building and training a multi-level network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = keras.utils.get_file(fname=\"auto-mpg.data\", origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "# The data has the following coluns\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "            'Acceleration', 'Model Year', 'Origin Country']\n",
    "# Read in the file into a Pandas Dataset\n",
    "raw_dataset = pd.read_csv(data_file, names=column_names,\n",
    "                  na_values = \"?\", comment='\\t',\n",
    "                  sep=\" \", skipinitialspace=True)\n",
    "# We will discard any rows that contain data with missing values\n",
    "raw_dataset = raw_dataset.dropna()\n",
    "raw_dataset.drop(['Model Year', 'Origin Country'], axis=1)\n",
    "raw_dataset.to_csv('simple.csv', index=False, header=False)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.genfromtxt('simple.csv', delimiter=',')\n",
    "X_data = my_data[:,1:].astype(np.float16)\n",
    "y_data = my_data[:,0].astype(np.float16)\n",
    "\n",
    "# Print out the first 5 records\n",
    "for i in range(5):\n",
    "    print(\"X_data = {}\\t y_data = {}\".format(X_data[i], y_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the shape of our training samples using the _shape_ attribute.\n",
    "\n",
    "In the case of __X_data__ the shape is (392, 7).\n",
    "- The first number (392) is the number of training samples\n",
    "- The second number (7) is the number of features in each training sample. We need this to define the size of the input on our input layer\n",
    "\n",
    "In the case of __y_data__ the shape is (392,)\n",
    "- The first number (392) is the number of training samples\n",
    "- It doesn't have a second number since __y_data__ is a list of number so each training sample correspondes to a single output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_data is {}\".format(X_data.shape))\n",
    "print(\"Shape of y_data is {}\".format(y_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build our model.\n",
    "\n",
    "Previously we only create a single layer network. In this exercise we are going to create a Multi-layer network. It will consist of:\n",
    "\n",
    "__An Input layer__: we create this in the same way as we have done before but given our data is a bit more complex we will want to increase the _number_of_nodes_ from 1 to some higher value such as 32, 64 or 128. The size of the features should be set to the number of features for each sample in X_data.\n",
    "\n",
    "In this exercise, change the values for _units_ and _input_shape_ to replace the value _None_ with more appropriate values.\n",
    "\n",
    "__A Hidden layer__: we simply just _One or more_  Dense layers but since this is not an input layer we don't specify the input shape (Keras works this out for us). So we just need to specify the number of nodes and an activation function `model.add( keras.layers.Dense(units=??, activation=tf.nn.relu) )`\n",
    "\n",
    "In this exercise, change the value for _units_ to replace the value _None_ with more appropriate values. Optionally, one or more additional layers.\n",
    "\n",
    "__An Output layer__: this is the layer that will produce the prediction and is just another Dense layer but the number of units must match the number of target features (1) in our __y_data__\n",
    "\n",
    "In this exercise, change the value for _units_ to replace the value _None_ with the appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# YOUR CHANGES START HERE\n",
    "\n",
    "# Input Layer\n",
    "model.add(keras.layers.Dense(units=None, activation=tf.nn.relu, input_shape=[None]) )\n",
    "\n",
    "# Hidden Layer\n",
    "model.add( keras.layers.Dense(units=None, activation=tf.nn.relu) )\n",
    "\n",
    "# Output Layer - we want a single value to be output so our output layer has a single unit\n",
    "model.add( keras.layers.Dense(None) )\n",
    "\n",
    "# YOUR CHANGES END HERE\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(keras.optimizers.RMSprop(0.001), loss='mean_squared_error')\n",
    "\n",
    "# Produce Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our model, specify the number of epochs to train for. Aim to get the _loss_ value below 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_data, y_data, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Learning Points\n",
    "You have now created a set of models to 'solve' some toy datasets. The key points to remember from this exercise are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks are like Onions...they have layers\n",
    "At a simplistic level a Neural Network can be thought of as a series of layers.\n",
    "\n",
    "__Input Layer__: this layer accepts the raw inputs and passes them to the network for processing.  All Neural Networks have this kind of layer. These layers primarily take the data from the outside for processing and typically don't have any learning associted with them. Keras has a special network layer called __Input__ that we can use for this purpose but we can also specify the input as part of the first layer.\n",
    "\n",
    "__Hidden Layers__: Networks may have one or more hidden layers, these are layers that sit behind the Inputput layer and perform the learning. Some simple networks might only have 1 layer but complex networks can have many thousands of hidden layers. \n",
    "\n",
    "We can add as many hidden layers as we want but there are limits due to the way that Optimisation algorithms work. This has lead to more advance architectures to overcome what is known as the __Vanishing Gradient__ problem.\n",
    "\n",
    "__Output Layer__: networks contain an output layer that takes the data from the previous layers and marshals this into an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about your input data\n",
    "As data passes between layers the shape (dimentions) of the data often change and within the model, Keras does an excellent job of determining these changes and so we don't need to be concerned about it.\n",
    "\n",
    "Howver, Keras understands little about the interface into the model and so we must specify the shape of the input at the _Input layer_. This needs to match the shape of the data we are passing into the model. To do this we need to look at the shape of the data for a single training instance and use this to tell Keras what shape the data is.\n",
    "\n",
    "We don't need to tell Keras how many training instance we have, only the shape of the training isntance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about your output data\n",
    "Any model we create aims to produce an output and so we need to consider the shape of our output. Typically if we are predicting a single value (e.g. the next number in a sequence) then our _Output Layer_ will be a _Dense_ layer with a single unit. Later we will see instance were we need more than 1 unit in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
