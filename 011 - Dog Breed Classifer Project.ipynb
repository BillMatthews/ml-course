{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Classifer Project\n",
    "In this workbook you will build a model to classify the breed of a dog from images. This is based on the Kaggle Dog Breed Identification Challenge (https://www.kaggle.com/c/dog-breed-identification)\n",
    "\n",
    "The task is to learn a model that classifies an image of a dog into 1 of 120 dog breeds. Like the Cat or Dog exercises, the images are real-world images so there is a great deal of variety in the data that your model will need to account for.\n",
    "\n",
    "As this is a Project, the workbook only gives you a skelton to work with, how you decide to solve this is up to you. No doubt you will want to refer back to previous exercises to find code snipets you can copy and adapt to this purpose.\n",
    "\n",
    "## Important\n",
    "This exercise is not meant to be straightforward, you will be given some skeleton code but you will need to create much of the model yourself and make more descisons about design and training your model.\n",
    "\n",
    "In part it is to consolidate your knowledge but also to expose you to the often iterative nature of building and training models.\n",
    "\n",
    "We usually allocate about 1hr to this exercise so you have plenty of time to experiment with different options in a group and iternative manner, you should have time to fully train a few different models.\n",
    "\n",
    "Don't Panic - this is not a test so if you need assistance or guidance just ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages\n",
    "We are using the Python programming language and a set of Machine Learning packages - Importing packages for use is a common task. For this workshop you don't really need to pay that much attention to this step (but you do need to execute the cell) since we are focusing on building models. However the following is a description of what this cell does that you can read if you are interested.\n",
    "\n",
    "### Description of imports (Optional)\n",
    "You don't need to worry about this code as this is not the focus on the workshop but if you are interested in what this next cell does, here is an explaination.\n",
    "\n",
    "|Statement|Meaning|\n",
    "|---|---|\n",
    "|__import tensorflow as tf__ |Tensorflow (from Google) is our main machine learning library and we performs all of the various calculations for us and so hides much of the detailed complexity in Machine Learning. This _import_ statement makes the power of TensorFlow available to us and for convience we will refer to it as __tf__ |\n",
    "|__from tensorflow import keras__ |Tensorflow is quite a low level machine learning library which, while powerful and flexible can be confusing so instead we use another higher level framework called Keras to make our machine learning models more readable and easier to build and test. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import numpy as np__ |Numpy is a Python library for scientific computing and is commonly used for machine learning. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import matplotlib.pyplot as plt__ |To visualise what is happening in our network we will use a set of graphs and MatPlotLib is the standard Python library for producing Graphs so we __import__ this to enable us to make pretty graphs.|\n",
    "|__%matplotlib inline__| this is a Jupyter Notebook __magic__ commmand that tells the workbook to produce any graphs as part of the workbook and not as pop-up window.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following cell contains a set of helper functions that makes our models a little clearer. We will not be going through these functions (since they require Python knowlege) so just make sure you have run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to stop ImageFile load failing for truncated images (known issue)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # Download and extract the Data Set\n",
    "    # Original Source is http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
    "    # However Udacity have created a set with Training and Test images set-up\n",
    "    source_url = \"https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\"\n",
    "    # Download the data \n",
    "\n",
    "    zip_file = tf.keras.utils.get_file(origin = source_url,\n",
    "                                            fname='dogImages.zip',\n",
    "                                            extract = True)\n",
    "    # Grab the location of the unzipped data\n",
    "    base_dir, _ = os.path.splitext(zip_file)\n",
    "\n",
    "    # Define the path to the Training and Validation Datasets\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'valid')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    return train_dir, validation_dir, test_dir\n",
    "\n",
    "def get_dog_breed_classes(data_dir):\n",
    "    return os.listdir(data_dir)\n",
    "    \n",
    "def showImageGrid(image_dir, num_rows=2, num_cols=4):  \n",
    "  image_labels = os.listdir(image_dir)\n",
    "  num_pix = num_rows * num_cols\n",
    "  # Index for iterating over images\n",
    "  pic_index = 0\n",
    "  # Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(num_cols * 4, num_rows * 4)\n",
    "\n",
    "  pic_index += num_pix\n",
    "  next_pix = [os.path.join(image_dir, fname) \n",
    "                  for fname in image_labels[pic_index-num_pix:pic_index]]\n",
    "  \n",
    "  for i, img_path in enumerate(next_pix):\n",
    "    # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(num_rows, num_cols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "  plt.show()\n",
    "    \n",
    "def predictImageContent(model):\n",
    "  import numpy as np\n",
    "  from google.colab import files\n",
    "  from keras.preprocessing import image\n",
    "\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  for fn in uploaded.keys():\n",
    "\n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size=(image_size, image_size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    pred_class = np.argmax(classes[0])\n",
    "    print(\"{} is a {}\".format(fn, dog_classes[pred_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "We will download the Dog Breed dataset, extract it to your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, validation_dir, test_dir = get_data()\n",
    "dog_classes = os.listdir(train_dir)\n",
    "print(\"Total number of dog breed classes: {}\".format(dog_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's looks at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images from the Training folder\n",
    "print(\"Training Images\")\n",
    "showImageGrid(train_dir, num_rows=4, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Generators\n",
    "In our dataset we have seperate sets of data for:\n",
    "- training\n",
    "- validation\n",
    "- testing\n",
    "\n",
    "The path to these are given in the variables:\n",
    "- __train_dir__\n",
    "- __validation_dir__\n",
    "- __test_dir__\n",
    "\n",
    "Since we are working with images on the file-system we will need to create ImageDataGenerators for each of the training data set.\n",
    "\n",
    "Below we have created the ImageDataGenerator for the training dataset. You will need to create your own generators for the validation and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want all our images to be re-sized to 160 x 160 pixels\n",
    "image_size = 160\n",
    "\n",
    "# For Training we want to use batches of 32 images at a time\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator for the Training data\n",
    "The following cell contains the code to create a basic generator for the Training data (stored in the __train_dir__ folder).\n",
    "### Optional Exercise\n",
    "This Generator does not include any options for image augmentation. If you want, you can add these to this Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Generator\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,  # Source directory for the training images\n",
    "                target_size = (image_size, image_size),\n",
    "                batch_size = batch_size,\n",
    "                # We are performing a multi-class Classification\n",
    "                class_mode = 'categorical',\n",
    "                classes=dog_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator for Valdiation data\n",
    "### Exercise\n",
    "Create a Data Generator for the Validation data - this is stored in the __validation_dir__ folder.\n",
    "\n",
    "Use the above step as a guide and make the necessary changes to make it specific to the Validation Data\n",
    "\n",
    "Optionally you can include Data Augmentation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator for Testing data\n",
    "### Exercise\n",
    "Create a Data Generator for the Testing data - this is stored in the __test_dir__ folder.\n",
    "\n",
    "Use the above step as a guide and make the necessary changes to make it specific to the Validation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design your Model\n",
    "With the data loaded and the Data Generators created, we can now design our network. The design of your network is entirely up to you.\n",
    "\n",
    "You could:\n",
    "- Create CNN network\n",
    "- Use Transfer Learning\n",
    "\n",
    "### Exercise\n",
    "Discuss with your team a set of network designs to try and each of you build a different one. This enables you to compare different options.\n",
    "\n",
    "\n",
    "Your best sources are the last 2 workbooks as they cover a similar domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# TODO: YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(tf.keras.layers.Dense(len(dog_classes), activation=tf.nn.softmax))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.AdamOptimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print out a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your Model\n",
    "### Exercise\n",
    "You are now ready to train your model. We have provided you with the code to train the model, but you need to decide the number of epochs to train for and the early stopping criteira (patience level).\n",
    "\n",
    "__NOTE__: If you have opted to use Transfer learning then you may need to create additional cells to fine tune the model (as per the last workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f7dbfc0617d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Stop early if our Validation Loss stagnates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Review the number of epochs and the early stoping criteria (patience).\n",
    "# Change these if you think it necessaryt\n",
    "epoch = 10\n",
    "\n",
    "# Stop early if our Validation Loss stagnates\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the mode\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    epochs=epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLossAndAccuracy(transfer_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model\n",
    "Our Training Data includes a test data set so we will use this to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against our Test Set\n",
    "loss, accuracy = model.evaluate_generator(test_generator)\n",
    "print(\"Test Loss {:.4f}\".format(loss))\n",
    "print(\"Test Accuracy {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "In your teams, consider the task we have been working on (dog breed classification) and consider the following questions:\n",
    "\n",
    "- What would be the Human Level Performance for this task? And how did our model do compared to that expectation?\n",
    " \n",
    "If your model hasn't performed as well as you think it could have then consider either continuting to train the model for more epochs or perform some fine-tuning to try and get this closer to a Human Level Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Model\n",
    "The Accuracy gives us a view of how well the model performed against our data, we now need to consider how we might test this model to look for potential issues.\n",
    "\n",
    "The following cell will allow you to select a file of your own choosing to test our current model.\n",
    "\n",
    "### Exercise\n",
    "Think about the task we are trying to solve (predicting the breed of a dog) and in your teams consider:\n",
    " - What dog breeds are easy to identify?\n",
    " - What dog breeds might a human confuse?\n",
    "\n",
    "Use the cell below to try some images out \n",
    "- you can download images to your machine from sites such as https://pixabay.com/ and run the cell below to load and classify the image - Use Small images if you can (makes the testing a bit faster)\n",
    "- Find 1 image of a Cat and 1 image of a Dog that you think your model should easily identify correctly.\n",
    "- Find 1 image of a Cat and 1 image of a Dog that you think might be challenging for your model to identify correctly (e.g. a Dog that doesn't look like a dog, or a Cat that looks like a Dog).\n",
    "- NOTE: This only works in a CoLab environment.\n",
    "\n",
    "\n",
    "Were you able to fool the model in a way that a human would not have been fooled?\n",
    "- If so what should we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictImageContent(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "In your teams, prepre a short report (5-8 mins) that outlines:\n",
    "- The model you found worked best\n",
    "- Your Testing Strategy\n",
    "- Your Key Findings\n",
    "\n",
    "We will then present to each other and debrief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
