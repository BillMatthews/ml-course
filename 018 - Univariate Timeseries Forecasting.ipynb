{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Time Series Forecasting\n",
    "The workbook demonstrates forecasting time series values using a single value (_Univariate_).\n",
    "\n",
    "By now you should be familiar with foundation networks such as Dense, CNNs and LSTMs and we will use these in this workbook to forecast the next value in the sequence.\n",
    "\n",
    "The dataset we will be used contains two variables but for the time being we will only use one of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages\n",
    "We are using the Python programming language and a set of Machine Learning packages - Importing packages for use is a common task. For this workshop you don't really need to pay that much attention to this step (but you do need to execute the cell) since we are focusing on building models. However the following is a description of what this cell does that you can read if you are interested.\n",
    "\n",
    "### Description of imports (Optional)\n",
    "You don't need to worry about this code as this is not the focus on the workshop but if you are interested in what this next cell does, here is an explaination.\n",
    "\n",
    "|Statement|Meaning|\n",
    "|---|---|\n",
    "|__import tensorflow as tf__ |Tensorflow (from Google) is our main machine learning library and we performs all of the various calculations for us and so hides much of the detailed complexity in Machine Learning. This _import_ statement makes the power of TensorFlow available to us and for convience we will refer to it as __tf__ |\n",
    "|__from tensorflow import keras__ |Tensorflow is quite a low level machine learning library which, while powerful and flexible can be confusing so instead we use another higher level framework called Keras to make our machine learning models more readable and easier to build and test. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import numpy as np__ |Numpy is a Python library for scientific computing and is commonly used for machine learning. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import matplotlib.pyplot as plt__ |To visualise what is happening in our network we will use a set of graphs and MatPlotLib is the standard Python library for producing Graphs so we __import__ this to enable us to make pretty graphs.|\n",
    "|__%matplotlib inline__| this is a Jupyter Notebook __magic__ commmand that tells the workbook to produce any graphs as part of the workbook and not as pop-up window.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following cell contains a set of helper functions that makes our models a little clearer. We will not be going through these functions (since they require Python knowlege) so just make sure you have run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def print_timeseries(generator, num_samples=0):\n",
    "    pairs = len(generator[0][0])\n",
    "    if (num_samples > 0 and num_samples < pairs ):\n",
    "        pairs = num_samples\n",
    "    \n",
    "    for i in range(pairs):\n",
    "        x = generator[0][0][i]\n",
    "        \n",
    "        y = generator[0][1][i]\n",
    "        \n",
    "        print(\"[%s] => [%s]\" % (x, y))\n",
    "\n",
    "def create_target_series_for_generator(data, skip_output=0, output_length=1):\n",
    "    # The Generator will deal selecting the next in the sequence\n",
    "    # but if our predictions are skiping steps we need to shift our data a bit\n",
    "    shifted_data = data[skip_output:]\n",
    "   \n",
    "    # Now we loop through this shifted data set and collect sucessive  pairs\n",
    "    # and add them to our target_seq\n",
    "    target_seq = []\n",
    "    # Stop before we run out of output groups\n",
    "    pairs = len(shifted_data) - output_length\n",
    "    for i in range(pairs):\n",
    "        item = []\n",
    "        for j in range(output_length):\n",
    "            item.append(shifted_data[i+j])\n",
    "        target_seq.append(item)\n",
    "    return target_seq\n",
    "\n",
    "def printLoss(history):\n",
    "    history_dict = history.history\n",
    "    loss = history_dict['loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    # \"bo\" is for \"blue dot\"\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def get_y_from_generator(generator):\n",
    "    y = None\n",
    "    for i in range(len(generator)):\n",
    "        batch_y = generator[i][1]\n",
    "        if y is None:\n",
    "            y = batch_y\n",
    "        else:\n",
    "            y = np.append(y, batch_y)\n",
    "    y = y.reshape((-1,1))\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "The data we are using contains monthly figures for the number of Passengers (in thousands) and the Mean Monthly Temperature for the associated Month.\n",
    "\n",
    "For this workbook we will only be working with the number of Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some sample data\n",
    "dataset = pd.read_csv('https://github.com/BillMatthews/ml-course/blob/master/passengers_and_temps.csv?raw=true',  engine='python')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_data = np.array(dataset['Passengers'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data\n",
    "The following cell plots a graph showing the number of Passengers travelling per month over a 12 year period.\n",
    "\n",
    "You can see from the graph that the data shows:\n",
    "- A general upward trend with each each of data being higher than the last\n",
    "- A seasonality to the data where each year has a similar shape but differs in the ranges of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Passengers'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our data\n",
    "We now need to prepare our data and create a TimeseriesGenerator to work with. \n",
    "\n",
    "In this workbook we are only looking to predict the passenger levels for the next month given the previous few months of data.\n",
    "\n",
    "### Normalise our data\n",
    "As before we need to normalise our data so that our values are in the range 0-1 to help learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "timeseries_data = scaler.fit_transform(timeseries_data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use TimeseriesGenerators but before we create them we need to split our data into Training and Testing sets.\n",
    "\n",
    "### Exercise\n",
    "Look at the graph above, at what point should we make the split?\n",
    "\n",
    "If you rememebr from the previous workbook we want our Testing set to contain any Seasonality and Trends present in our Training data. Additionally, we usually take Testing data from the most recent data.\n",
    "\n",
    "Set the value below to make the split - this is in months so a value between 1 and 144 is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_after = 120\n",
    "\n",
    "train_data = timeseries_data[:testing_data_after]\n",
    "test_data = timeseries_data[testing_data_after:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create our TimeseriesGenerators for training and testing. In this workbook we are only predicing the next month ahead but we need to decide on how many historical months we will use to forecast ahead\n",
    "\n",
    "### Exercise\n",
    "How many months of data should we use as our features? 1 month, 3 months, 6 months? Some other value?\n",
    "\n",
    "In the next cell you can specify the number of months to use as features in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify the number of months you want to use as your features\n",
    "feature_months = 6\n",
    "\n",
    "# Create our TimeseriesGenerator for Training\n",
    "training_generator = TimeseriesGenerator (data = train_data,\n",
    "                                    targets = train_data,\n",
    "                                    length = feature_months)\n",
    "\n",
    "# Create our TimeseriesGenerator for Testing\n",
    "testing_generator = TimeseriesGenerator (data = test_data,\n",
    "                                    targets = test_data,\n",
    "                                    length = feature_months)\n",
    "\n",
    "# Print out the start of our original series\n",
    "print(train_data[:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "# print out a sample of our training data to check our generators are correct\n",
    "print_timeseries(training_generator, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our Model\n",
    "We are now in a position to design our model using your own choice of networks architecture. We will provide a skeleton for you but it will be up to you to complete the model and train it.\n",
    "\n",
    "## Exercise\n",
    "Work in your groups to decide what network archiecture you will use and each train a different network to compare the results.\n",
    "\n",
    "Some options include:\n",
    " - Create a network consisting of a series of Dense layers\n",
    " - Create a network using a series of CNN layers\n",
    " - Create a network using an LSTM\n",
    "\n",
    "We have provided you with starter code for each of the 3 options. You should complete the cell for the model you are building and only run that cell. \n",
    "\n",
    "Each Cell has been set to be a _Markup_ cell so you will need to change the cell type on the one you are building to be _Code_. \n",
    "\n",
    "Ask if you are not sure how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Level Network using Dense Nodes\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(keras.layers.Input(shape=(feature_months, 1)))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden Layers\n",
    "# TODO: Add one or more hidden layers\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Network\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(keras.layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu', \n",
    "                     input_shape=[feature_months, 1]))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(keras.layers.Conv1D(filters=128, kernel_size=2, activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Network\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.LSTM(units = feature_months*2, input_shape=(feature_months, 1)))\n",
    "\n",
    "# TODO: Optionally add one or more Dense layers\n",
    "model.add(keras.layers.Dense(128))\n",
    "\n",
    "# Output layer\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll train for some epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# Stop early if our Validation Loss stagnates\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "# Train our model\n",
    "history = model.fit_generator(training_generator, epochs = max_epochs,\n",
    "                   callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your model\n",
    "With the model trained we can evaluate the model against our training data.\n",
    "\n",
    "__Note__: We only have 144 data points so our models are probably not going to be that accurate.\n",
    "\n",
    "## Exercise\n",
    "Look at the plot of the model loss during training; if the curve has shallowed out and not changing much then the model has probably reached it's limit of learning. If not continue to train the model for more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLoss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "We can now run our model against the previously unseen error and get a measure of how good the model is (Mean Squared Error). \n",
    "\n",
    "While this may look small we have to remember that we normalised the data to the range 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.evaluate_generator(testing_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Predicted and Actual forecast\n",
    "Let's now plot our predicted values against the actual values.\n",
    "\n",
    "Before we can do this we need to extract some values from our testing generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_test = model.predict(testing_generator)\n",
    "y_actual = get_y_from_generator(testing_generator)\n",
    "\n",
    "\n",
    "# Plot graph of predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_actual, label='Actual')\n",
    "plt.plot(y_pred_test, label='Prediction')\n",
    "plt.title(\"Prediction\")\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
